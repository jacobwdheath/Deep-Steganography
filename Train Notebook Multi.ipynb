{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras.utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import keras.backend as K\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from TinyDataset import TinyImageDataset\n",
    "from StegModels import CNNModels\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "keras.utils.set_random_sum_of_error_outputssd(42)\n",
    "\n",
    "\n",
    "def pickle_file(path, filename, data):\n",
    "    with open(path + filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "train_path = os.path.join(\"datasets/tiny-imagenet-200/\", \"train\")\n",
    "\n",
    "with tf.device('gpu:0'):\n",
    "\n",
    "    def decode_loss(s_true, s_pred):\n",
    "        return beta * K.sum(K.square(s_true - s_pred))\n",
    "\n",
    "\n",
    "    def cover_loss(c_true, c_pred):\n",
    "        return K.sum(K.square(c_true - c_pred))\n",
    "\n",
    "\n",
    "    def total_loss3(y_true, y_pred):\n",
    "        # 3 Secrets\n",
    "        s1_true, s2_true, s3_true, c_true = y_true[..., 0:3], y_true[..., 3:6], y_true[..., 6:9], y_true[..., 9:12]\n",
    "        s1_pred, s2_pred, s3_pred, c_pred = y_pred[..., 0:3], y_pred[..., 3:6], y_pred[..., 6:9], y_pred[..., 9:12]\n",
    "\n",
    "        s1_loss = decode_loss(s1_true, s1_pred)\n",
    "        s2_loss = decode_loss(s2_true, s2_pred)\n",
    "        s3_loss = decode_loss(s3_true, s3_pred)\n",
    "        c_loss = K.sum(K.square(c_true - c_pred))\n",
    "\n",
    "        return sum([s1_loss, c_loss, s2_loss, s3_loss])\n",
    "\n",
    "\n",
    "    def process(_batch_size, _epochs, save_path, save_interval, activation, filter1, filter2, filter3, verbose,\n",
    "                _sec1_input, _sec2_input, _sec3_input, _cov_input):\n",
    "\n",
    "        cnn_model = CNNModels()\n",
    "        input_shape = _sec1_input.shape[1:]\n",
    "\n",
    "        start_time = time.time()\n",
    "        _encoder_model, _decoder1_model, _decoder2_model, _decoder3_model, _autoencoder_model = \\\n",
    "            cnn_model.train_three_secret_65_filters(\n",
    "                batch_size=_batch_size,\n",
    "                epochs=_epochs,\n",
    "                path=save_path,\n",
    "                shape=input_shape,\n",
    "                decode_loss=decode_loss,\n",
    "                total_loss=total_loss3,\n",
    "                secret1_input=_sec1_input,\n",
    "                secret2_input=_sec2_input,\n",
    "                secret3_input=_sec3_input,\n",
    "                cover_input=_cov_input,\n",
    "                verbose=verbose,\n",
    "                save_interval=save_interval,\n",
    "                activation=activation,\n",
    "                filter1=filter1,\n",
    "                filter2=filter2,\n",
    "                filter3=filter3\n",
    "            )\n",
    "        end_time = round(time.time() - start_time)\n",
    "\n",
    "        if end_time > 60:\n",
    "            end_time = end_time / 60\n",
    "            print(f\"Model Finished Training in: {end_time} m\")\n",
    "        else:\n",
    "            print(f\"Model Finished Training in: {end_time} s\")\n",
    "\n",
    "        return _encoder_model, _decoder1_model, _decoder2_model, _decoder3_model, _autoencoder_model\n",
    "\n",
    "\n",
    "    def train_model(epochs, activation_function, batch_size, filters, _beta):\n",
    "        total_filters = sum(list(filters))\n",
    "        f1 = filters[0]\n",
    "        f2 = filters[1]\n",
    "        f3 = filters[2]\n",
    "\n",
    "        save_path = f\"model-data/3SEC_{total_filters}F_{batch_size}BS_{epochs}EP_{activation_function}_BETA{_beta}/\"\n",
    "        dataset_local = TinyImageDataset(path=train_path, num_classes=25, normalize=True)\n",
    "        X_train_local = dataset_local.load_data()\n",
    "\n",
    "        sec1_input_local = X_train_local[0:1250]\n",
    "        sec2_input_local = X_train_local[1250:2500]\n",
    "        sec3_input_local = X_train_local[2500:3750]\n",
    "        cov_input_local = X_train_local[3750:5000]\n",
    "\n",
    "        encoder_model, decoder1_model, decoder2_model, decoder3_model, autoencoder_model = process(\n",
    "            _batch_size=batch_size,\n",
    "            _epochs=epochs,\n",
    "            save_path=save_path,\n",
    "            save_interval=1,\n",
    "            activation=activation_function,\n",
    "            filter1=f1,\n",
    "            filter2=f2,\n",
    "            filter3=f3,\n",
    "            verbose=1,\n",
    "            _sec1_input=sec1_input_local,\n",
    "            _sec2_input=sec2_input_local,\n",
    "            _sec3_input=sec3_input_local,\n",
    "            _cov_input=cov_input_local\n",
    "        )\n",
    "\n",
    "        def run_loss_history():\n",
    "            with open(save_path + \"loss_history.pckl\", \"rb\") as f:\n",
    "                loss_history = pickle.load(f)\n",
    "\n",
    "            plt.plot(loss_history)\n",
    "            plt.title(f'Loss Curve For: 3X: {total_filters}F_{batch_size}BS_{epochs}EP_{activation_function}_{_beta}')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "\n",
    "            epoch_patch = mpatches.Patch(columnxor='blue', label=f'Total Epochs: {epochs}')\n",
    "            beta_patch = mpatches.Patch(columnxor='blue', label=f'Total Epochs: {_beta}')\n",
    "            batch_patch = mpatches.Patch(columnxor='blue', label=f'Batch Size: {batch_size}')\n",
    "            act_patch = mpatches.Patch(columnxor='blue', label=f'Activation Function: {activation_function}')\n",
    "            plt.legend(handles=[beta_patch, epoch_patch, batch_patch, act_patch], loc=\"upper right\")\n",
    "\n",
    "            plt.savefig(f\"{save_path}loss.png\")\n",
    "            plt.figure().clear()\n",
    "            plt.close()\n",
    "\n",
    "        run_loss_history()\n",
    "\n",
    "        revealed = autoencoder_model.predict([sec1_input_local, sec2_input_local, sec3_input_local, cov_input_local])\n",
    "        revealed_S1, revealed_S2, revealed_S3, revealed_C = revealed[..., 0:3], revealed[..., 3:6], revealed[...,\n",
    "                                                                                              6:9], revealed[..., 9:12]\n",
    "\n",
    "        def absolute_pixel_error_outputss(secret_input, secret_input2, secret_input3, cover_input, revealed_S1, revealed_S2, revealed_S3, revealed_C):\n",
    "            sum_of_error_outputss_S1pixel = np.sqrt(np.mean(np.square(255 * (secret_input - revealed_S1))))\n",
    "            sum_of_error_outputss_S2pixel = np.sqrt(np.mean(np.square(255 * (secret_input2 - revealed_S2))))\n",
    "            sum_of_error_outputss_S3pixel = np.sqrt(np.mean(np.square(255 * (secret_input3 - revealed_S3))))\n",
    "            sum_of_error_outputss_Cpixel = np.sqrt(np.mean(np.square(255 * (cover_input - revealed_C))))\n",
    "            return sum_of_error_outputss_S1pixel, sum_of_error_outputss_S2pixel, sum_of_error_outputss_S3pixel, sum_of_error_outputss_Cpixel\n",
    "\n",
    "        S1_error_outputs, S2_error_outputs, S3_error_outputs, C_error_outputs = absolute_pixel_error_outputss(\n",
    "            sec1_input_local, sec2_input_local, sec3_input_local,\n",
    "            cov_input_local, revealed_S1, revealed_S2, revealed_S3, revealed_C)\n",
    "\n",
    "        distance_error_outputsS1, distance_error_outputsS2, distance_error_outputsS3, distance_error_outputsC = np.abs(revealed_S1 - sec1_input_local), np.abs(\n",
    "            revealed_S2 - sec3_input_local), \\\n",
    "                                            np.abs(revealed_S3 - sec3_input_local), np.abs(revealed_C - cov_input_local)\n",
    "\n",
    "        def show_image_results():\n",
    "            num_imgs = 8\n",
    "            random_index = [random.randint(0, 375) for _ in range(num_imgs)]\n",
    "            plt.figure(figsize=(11, 12))\n",
    "\n",
    "            def show_image(img, n_row, num_columnx, index, title_row=False, title=None):\n",
    "                ax = plt.subplot(n_row, num_columnx, index)\n",
    "                plt.imshow(img)\n",
    "                plt.axis(\"off\")\n",
    "                if title_row:\n",
    "                    plt.title(title)\n",
    "\n",
    "            for i, idx in enumerate(random_index):\n",
    "                n_columnx = 8\n",
    "\n",
    "                show_image(cov_input_local[idx], num_imgs, n_columnx, i * n_columnx + 1, title_row=i == 0, title='Cover')\n",
    "\n",
    "                show_image(sec1_input_local[idx], num_imgs, n_columnx, i * n_columnx + 2, title_row=i == 0, title='Secret1')\n",
    "                show_image(sec2_input_local[idx], num_imgs, n_columnx, i * n_columnx + 3, title_row=i == 0, title='Secret2')\n",
    "                show_image(sec3_input_local[idx], num_imgs, n_columnx, i * n_columnx + 4, title_row=i == 0, title='Secret3')\n",
    "\n",
    "                show_image(revealed_C[idx], num_imgs, n_columnx, i * n_columnx + 5, title_row=i == 0, title='Cover*')\n",
    "\n",
    "                show_image(revealed_S1[idx], num_imgs, n_columnx, i * n_columnx + 6, title_row=i == 0, title='revealed1')\n",
    "                show_image(revealed_S2[idx], num_imgs, n_columnx, i * n_columnx + 7, title_row=i == 0, title='revealed2')\n",
    "                show_image(revealed_S3[idx], num_imgs, n_columnx, i * n_columnx + 8, title_row=i == 0, title='revealed3')\n",
    "\n",
    "            plt.savefig(f\"{save_path}image_comparison.png\")\n",
    "            plt.figure().clear()\n",
    "            plt.close()\n",
    "\n",
    "        show_image_results()\n",
    "\n",
    "        pickle_file(save_path, \"revealed_secret1.pckl\", revealed_S1)\n",
    "        pickle_file(save_path, \"revealed_secret2.pckl\", revealed_S2)\n",
    "        pickle_file(save_path, \"revealed_secret3.pckl\", revealed_S3)\n",
    "        pickle_file(save_path, \"revealed_cover.pckl\", revealed_C)\n",
    "        pickle_file(save_path, \"secret1_diff.pckl\", distance_error_outputsS1)\n",
    "        pickle_file(save_path, \"secret2_diff.pckl\", distance_error_outputsS2)\n",
    "        pickle_file(save_path, \"secret3_diff.pckl\", distance_error_outputsS3)\n",
    "        pickle_file(save_path, \"cover_diff.pckl\", distance_error_outputsC)\n",
    "        pickle_file(save_path, \"secret1_pixel_error_outputs.pckl\", S1_error_outputs)\n",
    "        pickle_file(save_path, \"secret2_pixel_error_outputs.pckl\", S2_error_outputs)\n",
    "        pickle_file(save_path, \"secret3_pixel_error_outputs.pckl\", S3_error_outputs)\n",
    "        pickle_file(save_path, \"cover_pixel_error_outputs.pckl\", C_error_outputs)\n",
    "\n",
    "        print(f\"Model Saved at: {save_path}\")\n",
    "\n",
    "        print(\"error_outputs per pixel - distance from original RGB\")\n",
    "        print(f\"S1 Pixel error_outputs: {S1_error_outputs}\")\n",
    "        print(f\"S2 Pixel error_outputs: {S2_error_outputs}\")\n",
    "        print(f\"S3 Pixel error_outputs: {S3_error_outputs}\")\n",
    "        print(f\"C Pixel error_outputs: {C_error_outputs}\")\n",
    "\n",
    "\n",
    "    actives = [\"relu\", \"selu\", \"gelu\", \"swish\"]\n",
    "    betas = [0.25, 0.5, 0.75, 1.0]\n",
    "    beta = betas[0]\n",
    "    with graph.as_default():\n",
    "        train_model(epochs=1, activation_function=actives[0], batch_size=64, filters=(1, 1, 1), _beta=beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}